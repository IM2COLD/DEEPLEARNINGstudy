{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "머신러닝과 전통적인 통계 방법은 데이터 분석에 접근하는 데에 있어 몇 가지 중요한 차이가 있습니다. 여기에는 목표, 접근 방식, 모델 복잡성 등이 포함됩니다.\n",
        "\n",
        "1. **목표와 사용 방법:**\n",
        "   - 전통적인 통계 방법은 일반적으로 가설 검정, 매개 변수 추정 등과 같은 특정한 가정을 기반으로 데이터를 분석합니다. 이 방법은 데이터를 사용하여 모집단에 대한 결론을 도출하고, 이론적인 가정에 따라 데이터의 유의성을 평가합니다.\n",
        "   - 반면에 머신러닝은 데이터로부터 패턴을 발견하고 예측하는 데 중점을 둡니다. 목표는 일반적으로 데이터에서 특징을 추출하고 이러한 특징을 사용하여 미래의 데이터를 예측하는 것입니다.\n",
        "\n",
        "2. **모델의 복잡성:**\n",
        "   - 전통적인 통계 방법은 종종 간단한 선형 모델이나 일부 가정에 따라 파라미터를 추정하는데 중점을 둡니다. 이로 인해 모델이 해석하기 쉬워지지만, 복잡한 데이터 패턴을 모델링하기에는 제한이 있을 수 있습니다.\n",
        "   - 머신러닝에서는 일반적으로 복잡한 모델을 사용하여 데이터의 비선형적인 관계나 상호작용을 탐색합니다. 이는 고차원 데이터셋이나 비선형 패턴을 다룰 때 유용하지만, 모델의 해석이 어려울 수 있습니다.\n",
        "\n",
        "3. **데이터 요구량:**\n",
        "   - 전통적인 통계 방법은 상대적으로 적은 데이터를 기반으로 모델을 학습시킬 수 있습니다. 이는 모델의 파라미터 추정에 관심이 있기 때문에 가능합니다.\n",
        "   - 머신러닝에서는 보다 많은 데이터가 필요할 수 있습니다. 특히 복잡한 모델을 사용할 때는 데이터 양이 모델의 성능에 큰 영향을 미칠 수 있습니다.\n",
        "\n",
        "4. **일반화와 적용:**\n",
        "   - 전통적인 통계 방법은 보통 변수 간의 인과 관계를 추론하거나 실험 결과의 원인과 결과를 이해하는 데 중점을 둡니다.\n",
        "   - 머신러닝은 주로 예측 또는 패턴 인식을 위한 목적으로 사용됩니다. 예를 들어, 이미지 분류, 음성 인식, 자연어 처리 등 다양한 영역에서 적용됩니다.\n",
        "\n",
        "요약하면, 머신러닝과 전통적인 통계 방법은 목표, 모델의 복잡성, 데이터 요구량 및 적용 분야에서 중요한 차이를 보입니다."
      ],
      "metadata": {
        "id": "MO7BbWAhrJkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **베이즈 정리**\n",
        "\n",
        "전통적인 통계 분석과 머신러닝은 데이터를 분석하는 두 가지 주요 방법론입니다. 베이즈 분석은 전통적인 통계 분석의 한 형태로, 데이터와 관련된 불확실성을 다루는 데 중점을 둡니다. 이 방법론은 베이즈 정리를 기반으로 하며, 확률을 사용하여 가설을 수립하고 갱신하는 방식으로 작동합니다.\n",
        "\n",
        "베이즈 분석에서, 우리는 사전 정보와 새로운 데이터를 결합하여 사후 확률을 계산합니다. 이를 통해 우리는 데이터를 통해 얻은 정보를 이용하여 우리의 믿음이나 확신의 정도를 업데이트할 수 있습니다. 이러한 방식으로, 베이즈 분석은 불확실성을 고려하여 데이터를 해석하고, 이를 기반으로 의사 결정을 내릴 수 있는 강력한 도구가 됩니다.\n",
        "\n",
        "베이즈 분석은 복잡한 모델에도 적용할 수 있으며, 모델의 매개 변수에 대한 확률적인 관점을 제공합니다. 이러한 유연성은 머신러닝에서 많은 형태의 데이터를 다루는 데 도움이 될 수 있습니다. 그러나 베이즈 분석은 계산적으로 요구되는 비용이 많이 들기 때문에 대규모 데이터셋에 대한 적용이 제한될 수 있습니다.\n",
        "\n",
        "요약하면, 베이즈 분석은 전통적인 통계 분석의 한 형태로, 불확실성을 다루는 강력한 도구입니다. 이는 데이터를 해석하고 의사 결정을 내릴 때 유용하며, 머신러닝과 같은 분야에서도 많이 사용됩니다.\n",
        "\n",
        "> 베이즈 분석이 계산에 요구되는 비용이 많이 드는 이유\n",
        "\n",
        "베이즈 분석이 계산적으로 비용이 많이 드는 이유는 몇 가지가 있습니다.\n",
        "\n",
        "1. **적분 연산의 복잡성:** 베이즈 분석은 일반적으로 사후 확률 분포를 계산하기 위해 적분 연산을 수행해야 합니다. 특히 고차원의 매개 변수 공간이나 복잡한 모델의 경우, 이러한 적분 연산은 계산적으로 매우 비싸거나 혹은 심지어 해석할 수 없을 정도로 복잡해질 수 있습니다.\n",
        "\n",
        "2. **초기 정보의 선택:** 베이즈 분석에서는 사전 분포를 선택해야 합니다. 이 사전 분포를 결정하기 위해서는 도메인 지식이나 경험적인 정보가 필요합니다. 올바른 사전 분포를 선택하는 것은 분석의 정확성에 중요한 영향을 미칩니다.\n",
        "\n",
        "3. **MCMC와 유사한 방법의 사용:** 많은 베이지안 추론 방법은 Markov Chain Monte Carlo(MCMC)와 같은 샘플링 기법을 사용합니다. 이러한 방법은 수많은 샘플을 생성하여 사후 분포를 추정합니다. 이 과정은 많은 계산 자원과 시간을 필요로 합니다.\n",
        "\n",
        "4. **모델의 복잡성:** 베이지안 모델이 복잡해질수록 계산이 더욱 복잡해질 수 있습니다. 예를 들어, 계층적 모델이나 혼합 모델과 같은 복잡한 구조를 가진 경우, 추론 과정이 더 복잡해질 수 있습니다.\n",
        "\n",
        "이러한 이유로, 베이즈 분석은 계산적으로 요구되는 비용이 많이 들 수 있습니다. 이는 대규모 데이터셋이나 복잡한 모델을 다룰 때 특히 두드러집니다."
      ],
      "metadata": {
        "id": "sjBy2-Zqqw2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> 머신러닝, 특히 딥러닝은 수학적 이론이 비교적 부족하고, 근본적으로 engineering 분야에 해당된다. **머신러닝은 이론 물리학이나 수학과 달리 경험적 발견에 의해 주도되는 매우 실천적인 분야이고, 소프트웨어 및 하드웨어의 발전에 크게 의존한다.**"
      ],
      "metadata": {
        "id": "HUY7rLIGtIab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **초창기 신경망 : 역전파 알고리즘 경사 하강법**"
      ],
      "metadata": {
        "id": "TxTHGsdXuo0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **커널 방식**\n",
        "\n",
        "커널 함수는 머신러닝에서 주어진 데이터를 고차원의 특징 공간으로 매핑하는 함수입니다. 이러한 함수는 일반적으로 비선형 문제를 해결하기 위해 사용됩니다. 기본적으로 선형 분류나 회귀 모델은 데이터가 선형적으로 분리되는 것을 가정합니다. 그러나 실제 데이터는 종종 선형적으로 분리되지 않을 수 있습니다. 이런 경우 커널 함수를 사용하여 데이터를 고차원의 특징 공간으로 변환하면 비선형 문제를 선형적으로 해결할 수 있습니다.\n",
        "\n",
        "커널 함수는 주로 두 가지 특징을 갖습니다:\n",
        "\n",
        "1. **비선형 매핑(Nonlinear Mapping)**: 커널 함수는 입력 데이터를 고차원의 특징 공간으로 매핑하는 비선형 함수입니다. 이를 통해 데이터를 더 복잡한 형태로 변환하여 비선형 문제를 해결할 수 있습니다.\n",
        "\n",
        "2. **내적 계산(Inner Product Calculation)**: 커널 함수는 입력 데이터를 고차원으로 변환하는 것 외에도, 두 데이터 포인트 간의 내적(inner product)을 계산할 수 있어야 합니다. 내적 계산을 통해 커널 트릭을 사용하여 원래의 입력 공간에서는 계산이 어려운 고차원 특징 공간의 연산을 효율적으로 수행할 수 있습니다.\n",
        "\n",
        "가장 일반적으로 사용되는 커널 함수 중 하나는 **RBF(Radial Basis Function) 커널**입니다. RBF 커널은 데이터를 무한한 차원의 특징 공간으로 매핑하며, 이를 통해 다양한 형태의 비선형 결정 경계를 학습할 수 있습니다.\n",
        "\n",
        "커널 함수는 다양한 머신러닝 알고리즘에서 사용될 수 있으며, 주로 서포트 벡터 머신(SVM), 커널 PCA(Kernel Principal Component Analysis), 커널 리지 회귀(Kernel Ridge Regression) 등에서 사용됩니다.\n",
        "\n",
        "커널 함수의 선택은 데이터의 특성과 문제의 복잡성에 따라 달라질 수 있으며, 올바른 커널 함수를 선택하는 것이 모델의 성능에 큰 영향을 미칩니다."
      ],
      "metadata": {
        "id": "BYcLUSXXuhD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **머신러닝에서 svm을 사용해서 손글씨 숫자를 분류한다면 원시 픽셀값을 바로 사용하지는 못하고, 픽셀 히스토그램처럼 문제를 쉽게 만드는 유용한 표현을 수동으로 먼저 적용해주는 \"특성 공학\"이 필요한데, 딥러닝에서는 이를 완전히 자동화하기 떄문에 문제를 더 해결하기 쉽게 만들어준다.**\n",
        "\n",
        " 특성 공학은 머신러닝에서 매우 중요한 단계 중 하나입니다. 원시 데이터가 머신러닝 모델에 적용되기 전에 특성으로 변환되어야 할 때가 많습니다. 이는 모델이 문제를 효과적으로 해결할 수 있도록 도와주는 과정입니다.\n",
        "\n",
        "> 특성 공학의 목적은 다음과 같습니다:\n",
        "1. **데이터의 표현 변경**: 원시 데이터의 표현을 변경하여 모델이 문제를 더 잘 이해하고 처리할 수 있도록 돕습니다. 예를 들어, 이미지를 픽셀 단위로 사용하는 대신 히스토그램, 텍스트를 단어 또는 n-그램으로 표현하는 등의 방법을 사용할 수 있습니다.\n",
        "2. **모델의 성능 향상**: 적절한 특성 공학을 통해 모델의 성능을 향상시킬 수 있습니다. 예를 들어, 특정 도메인에 특화된 특성을 추가하거나, 불필요한 특성을 제거하여 모델의 복잡성을 줄일 수 있습니다.\n",
        "3. **차원 감소**: 고차원 데이터의 차원을 줄이는 것은 모델의 계산 효율성을 높이고, 과적합을 방지하는 데 도움이 될 수 있습니다.\n",
        "\n",
        "딥러닝의 주요 장점 중 하나는 특성 공학의 일부를 자동화할 수 있다는 것입니다. 심층 신경망은 원시 데이터에서 고수준의 특성을 추출하고 학습할 수 있는 능력을 갖추고 있습니다. 이는 다양한 문제에 대해 효과적인 특성을 학습할 수 있도록 하며, 특성 공학의 일부를 모델 내부에서 수행할 수 있게 해줍니다. 그러나 특성 공학은 여전히 머신러닝의 중요한 부분입니다. 특히 데이터가 제한되거나 고차원인 경우, 사전에 특성을 수동으로 설계하는 것이 모델의 성능을 향상시키는 데 도움이 될 수 있습니다. 또한, 특성 공학은 문제에 대한 도메인 지식을 활용하여 모델을 개선하는 데 중요한 역할을 합니다. 따라서, 머신러닝에서 특성 공학은 여전히 필수적인 단계입니다. 그러나 딥러닝이 특성 추출의 일부를 자동화하고 일반적인 문제에 대해 좋은 성능을 제공할 수 있다는 점은 인정되어야 합니다."
      ],
      "metadata": {
        "id": "MkoCvWgX8YXN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 얕은 학습 방법(shallow learning) :\n",
        "얕은 학습 방법은 연속된 표현 층을 독립적으로 학습한다. 전체 층의 수와 상관없이 항상 동일하게 첫번째 층이 동일한 양의 정보를 학습하기에, 이후에 연속되는 층은 전체 모델에 기여하는 바가 점차 줄어든다.\n",
        "\n",
        "얕은 학습 모델에서는 첫 번째 층이 다른 층에 비해 더 많은 정보를 학습하게 되어, 이후에 연속되는 층이 전체 모델에 기여하는 비중이 줄어들게 됩니다. 예를 들어, 4개의 층으로 이루어진 모델에서 첫 번째 층이 60%의 정보를 학습한다고 가정해 보겠습니다. 그런 다음 두 번째 층은 첫 번째 층에서 학습된 정보를 이용하여 추가적인 특성을 학습할 수 있지만, 이미 첫 번째 층에서 많은 정보를 학습했기 때문에 그 비중은 상대적으로 낮을 것입니다. 이러한 과정이 계속되면서 각 층의 기여도는 점차 감소하게 됩니다. 따라서 뒤로 갈수록 각 층이 최종 예측에 기여하는 정도가 줄어들게 됩니다. 이는 전체 모델의 효율성과 성능에 영향을 미칠 수 있습니다. 얕은 학습 방법에서는 층의 수가 적고 각 층이 전체적으로 높은 비중의 정보를 학습하는 것이 중요합니다. 그러나 **심층 학습 방법에서는 다양한 층이 서로 다른 수준의 추상화를 학습하여 전체적으로 더 복잡한 특징을 학습할 수 있습니다. 따라서, 얕은 학습 방법에서는 층의 수가 많은 경우에도 층 간의 정보 전달이 비효율적일 수 있으며, 이는 모델의 성능에 영향을 미칠 수 있습니다.**"
      ],
      "metadata": {
        "id": "tbGcsvYD_zRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Convnet**\n",
        "\n",
        " Convolutional Neural Networks (ConvNets 또는 CNNs)에서는 Conv2D 층과 MaxPooling 층을 여러 번 쌓아서 사용하는 경우가 많습니다. 이러한 경우에도 **각 층들이 동시에 학습됩니다.**\n",
        "\n",
        "Conv2D 층은 입력 이미지에서 특징을 추출하기 위해 컨볼루션 연산을 수행하고, 이를 통해 이미지의 공간적인 구조를 보존하면서 특징을 감지합니다. MaxPooling 층은 특징 맵의 크기를 줄여서 계산량을 감소시키고, 추출된 특징을 강화합니다. 이러한 층들을 여러 번 쌓아서 네트워크를 깊게 만들면, 모델은 입력 이미지의 저수준 특징부터 고수준 특징까지 계층적으로 학습(특징을 추출)할 수 있습니다. 이 과정에서 각 층들은 동시에 학습되며, 이전 층들의 출력에 영향을 받으면서 전체적으로 데이터의 표현을 학습합니다. 따라서, Conv2D 층과 MaxPooling 층을 여러 번 쌓은 ConvNet의 경우에도 각 층들이 동시에 학습되며, 이전 층들의 출력에 영향을 받으면서 전체적으로 데이터의 표현을 학습합니다."
      ],
      "metadata": {
        "id": "wT2fZpyN5TUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **이전의 머신러닝과는 다르게, 딥러닝 모델만이 가지는 데이터로부터 학습하는 2가지 특징**\n",
        "\n",
        "1. 층을 거치면서 점진적으로 더 복잡한 표현이 만들어진다.\n",
        "2. 이러한 점진적인 중가 표현이 공동으로 학습된다.\n",
        "\n",
        "- 얕은 학습 방법(tree, svm)은 간단한 변환을 통해 1,2개의 연속된 표현 공간으로만 data를 변환\n",
        "- 얕은 학습 방법은 연속된 표현 층을 독립적으로 학습하기에 전체 층의 수와 상관없이, 항상 동일하게 첫 번째 층이 동일한 양의 정보를 학습하기에, 이후에 연속되는 층은 전체 모델에 기여하는 바가 점점 줄어들게 된다."
      ],
      "metadata": {
        "id": "GeiKZyxMpJIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **동시에 학습된다?**\n",
        "\n",
        "> **딥러닝의 변환 능력은 모델이 모든 표현 층을 순차적이 아니라(즉, 탐욕적 방법이 아니라) 동시에 공동으로 학습하게 만든다.**\n",
        "\n",
        " 딥러닝 모델은 여러 층(layer)으로 구성되어 있습니다. 각 층은 데이터를 받아들이고 처리한 후, 그 결과를 다음 층으로 전달합니다. 이 때, 각 층은 데이터를 특정한 방식으로 변환(transform)합니다. 예를 들어, 이미지를 입력으로 받아들이는 딥러닝 모델의 첫 번째 층은 이미지의 특징을 추출할 수 있도록 필터를 적용합니다. 이러한 층들은 일반적으로 순차적으로 학습됩니다. 즉, 처음에는 첫 번째 층이 데이터를 받아들여서 변환하고, 그 결과를 다음 층으로 전달하여 다시 변환하고, 이 과정이 반복됩니다. 이런 방식은 각 층이 이전 층의 출력에만 의존하여 학습되는 것을 의미합니다.\n",
        "\n",
        "여기서 공동 특성 학습 능력이 나오는데, 이는 딥러닝 모델이 하나의 특성을 조정할 때마다 이에 의존하는 다른 모든 특성이 자동으로 조정된다는 것을 의미합니다. 이는 각 층이 서로 독립적으로 동작하는 것이 아니라, 서로의 출력에 의존하며 협력하여 특성을 학습하기 때문에 가능합니다. 이것은 모델이 새로운 데이터나 환경에 적응할 수 있는 유연성을 제공합니다. 이해를 돕기 위해 예를 들어보겠습니다. 딥러닝 모델은 이미지를 분류하는 작업을 수행할 때 각 층은 다양한 특징을 학습합니다. 예를 들어, 첫 번째 층은 간단한 선, 모서리 등의 낮은 수준의 특성을 감지할 수 있고, 두 번째 층은 이러한 낮은 수준의 특성을 조합하여 더 복잡한 패턴을 학습할 수 있습니다. 이런 식으로 각 층은 입력 데이터의 특성을 점진적으로 추상화하고 다음 층에 전달합니다. 이러한 과정에서 층 간의 상호 의존성이 발생하며, 이로 인해 모델은 새로운 데이터에 대해 유연하게 대응할 수 있습니다.\n",
        "\n",
        "> **이것은 모든 층이 서로 상호작용하며, 각 층이 다른 층들의 출력을 고려하여 동시에 학습된다는 의미입니다. 즉, 각 층이 서로의 출력에 영향을 주고 받으면서 데이터의 복잡한 표현을 학습합니다. 이러한 방식은 탐욕적인(greedy) 방법이 아니라고도 합니다. 탐욕적인 방법은 각 단계에서 가장 좋은 선택을 하는 것을 의미하는데, 이는 일부 기계 학습 알고리즘에서 사용되는 방법입니다. 하지만 딥러닝은 모든 층이 함께 학습되므로 탐욕적인 방법이 아니라고 말합니다. 이것은 딥러닝이 매우 복잡한 데이터 패턴을 학습할 수 있는 이유 중 하나입니다. 각 층이 서로 영향을 주고 받으며 동시에 학습되므로, 모델이 데이터를 더 효과적으로 이해하고 표현할 수 있습니다.**"
      ],
      "metadata": {
        "id": "yAsjoxPbs1vG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **딥러닝 모델은 모든 표현 층을 동시에 공동으로 학습한다 : 역전파 알고리즘 backpropagation algorithm**\n",
        "\n",
        "**딥러닝 모델이 모든 표현 층을 동시에 공동으로 학습한다는 개념은 전통적인 기계 학습 방법과 구별되는 중요한 특징 중 하나입니다. 이것은 역전파(backpropagation) 알고리즘을 통해 이루어집니다.** 역전파는 모델의 출력과 실제 정답 사이의 오차를 최소화하기 위해 각 층의 가중치와 편향을 조정하는 데 사용됩니다. 딥러닝 모델에서 각 층은 입력 데이터로부터 특정 수준의 표현을 학습합니다. 예를 들어, 첫 번째 층은 이미지의 간단한 특징을 감지하고, 두 번째 층은 이러한 특징을 조합하여 더 복잡한 패턴을 인식합니다. 이 과정은 순차적으로 이루어집니다. 그러나 딥러닝에서는 역전파를 사용하여 모든 층이 동시에 조정됩니다. 이는 각 층이 출력 오차에 기여하는 방식으로 역전파되는 그래디언트(gradient)를 사용하여 이루어집니다. 이렇게 하면 모든 층이 함께 최적화되며, 이는 각 층이 동시에 데이터의 다양한 특징을 추상화하고 학습할 수 있도록 합니다. 이런 방식으로, 각 층은 서로 독립적으로 특징을 추출하는 것이 아니라 전체 네트워크의 목적을 달성하기 위해 협력하여 작업합니다. 이는 종종 더 높은 수준의 추상화와 더 나은 성능을 달성하는 데 도움이 됩니다."
      ],
      "metadata": {
        "id": "KJWvVe9jmN2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### **역전파(backpropagation)**는 딥러닝에서 가장 중요한 학습 알고리즘 중 하나입니다. 이 알고리즘은 신경망의 각 층에 있는 가중치와 편향을 조정하여 입력 데이터와 실제 값 사이의 오차를 최소화하는 데 사용됩니다. 이를 통해 모델이 데이터를 학습하고 일반화할 수 있습니다.\n",
        "\n",
        "역전파 알고리즘은 주로 다음 세 단계로 구성됩니다:\n",
        "\n",
        "순전파 (Forward Propagation): 먼저, 입력 데이터가 네트워크를 통해 전달되고 출력이 생성됩니다. 이 과정에서 각 층은 입력을 받아 가중치와 편향을 사용하여 활성화 함수를 적용하여 출력을 생성합니다. 이러한 출력은 실제 값과 비교되어 오차를 계산하는 데 사용됩니다.\n",
        "\n",
        "오차 계산 (Error Calculation): 순전파 후, 모델의 출력과 실제 값 사이의 오차를 계산합니다. 이 오차는 일반적으로 손실 함수를 사용하여 정의됩니다. 손실 함수는 모델의 출력과 실제 값 사이의 차이를 측정하는 함수입니다. 대표적인 손실 함수로는 평균 제곱 오차(Mean Squared Error, MSE)나 교차 엔트로피 손실(Cross-Entropy Loss) 등이 있습니다.\n",
        "\n",
        "역전파 (Backward Propagation): 이 단계에서는 오차를 각 층에 거꾸로 전파하여 각 층의 가중치와 편향을 조정합니다. 이는 기울기 하강(Gradient Descent)과정을 통해 이루어집니다. 오차를 각 층으로 다시 전파하기 위해 체인 룰(Chain Rule)을 사용합니다. 즉, 오차를 이전 층으로 전파하기 위해 현재 층의 출력과 활성화 함수의 미분을 곱하여 전달합니다. 이렇게 하면 각 층의 가중치와 편향을 조정하여 출력 오차를 최소화할 수 있습니다.\n",
        "\n",
        "이러한 과정을 반복하여 모델을 학습시킵니다. 역전파를 통해 모델은 데이터의 패턴을 인식하고 일반화할 수 있는 가중치와 편향을 조정하게 됩니다."
      ],
      "metadata": {
        "id": "1nLRgMEHnlOQ"
      }
    }
  ]
}